{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO18Edq7wwdaxFueJdtPXO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnperl/Equity/blob/main/EquityGpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install --quiet yfinance numpy pandas scikit-learn tensorflow shap matplotlib nltk requests\n",
        "\n",
        "# Import Libraries\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import shap\n",
        "import requests\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, Input, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import os\n",
        "\n",
        "# Ensure necessary nltk data is downloaded\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# === User Input for Stock Selection ===\n",
        "stock_symbol = input(\"Enter stock symbol (e.g., TSLA for Tesla): \").strip()\n",
        "print(f\"Fetching data for stock: {stock_symbol}\")\n",
        "\n",
        "# === Fetch Historical Stock Data ===\n",
        "print(f\"Stock symbol: {stock_symbol}\")\n",
        "\n",
        "df = yf.download(stock_symbol, start=\"2010-01-01\", interval=\"1d\", auto_adjust=True)\n",
        "print(df.columns)\n",
        "print(df.head())  # Print the first few rows\n",
        "print(df.isnull().sum())\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"Stock data fetched successfully.\")\n",
        "\n",
        "if df.empty:\n",
        "    print(\"DataFrame is empty. Check the stock symbol or date range.\")\n",
        "\n",
        "\n",
        "# === Technical Indicators Calculation ===\n",
        "print(f\"Stock symbol (before indicators): {stock_symbol}\")\n",
        "print(\"Calculating technical indicators...\")\n",
        "try:\n",
        "    df[('50_MA', stock_symbol)] = np.nan #create the column.\n",
        "    df[('200_MA', stock_symbol)] = np.nan #create the column.\n",
        "    df[('Volatility', stock_symbol)] = np.nan #create the column.\n",
        "    df[('RSI', stock_symbol)] = np.nan #create the column.\n",
        "    df[('MACD', stock_symbol)] = np.nan #create the column.\n",
        "\n",
        "    df[('50_MA', stock_symbol)] = df[('Close', stock_symbol)].rolling(window=50).mean()\n",
        "    df[('200_MA', stock_symbol)] = df[('Close', stock_symbol)].rolling(window=200).mean()\n",
        "    df[('Volatility', stock_symbol)] = df[('Close', stock_symbol)].rolling(window=50).std()\n",
        "    df[('RSI', stock_symbol)] = 100 - (100 / (1 + (df[('Close', stock_symbol)].diff().rolling(14).mean() / df[('Close', stock_symbol)].diff().rolling(14).std())))\n",
        "    df[('MACD', stock_symbol)] = df[('Close', stock_symbol)].ewm(span=12, adjust=False).mean() - df[('Close', stock_symbol)].ewm(span=26, adjust=False).mean()\n",
        "    df = df.sort_index(axis=1)\n",
        "    print(\"Technical indicators calculated.\")\n",
        "except KeyError as e:\n",
        "    print(f\"KeyError during technical indicator calculation: {e}\")\n",
        "    print(df.columns)  # Print the columns to see what's available\n",
        "\n",
        "# === Sentiment Analysis ===\n",
        "def get_sentiment_score(stock, date):\n",
        "    try:\n",
        "        url = f\"https://newsapi.org/v2/everything?q={stock}&from={date}&to={date}&apiKey=afce3fd1c27d40d186f4f3a3b1639a5f\"  # Replace with your NewsAPI key\n",
        "        response = requests.get(url)\n",
        "        news_data = json.loads(response.text)\n",
        "\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        sentiment_scores = [analyzer.polarity_scores(article[\"title\"])['compound'] for article in news_data.get(\"articles\", [])]\n",
        "\n",
        "        return np.mean(sentiment_scores) if sentiment_scores else 0\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching sentiment: {e}\")\n",
        "        return 0\n",
        "\n",
        "if \"Sentiment\" in df.columns:\n",
        "    df = df.drop(columns=[\"Sentiment\"])\n",
        "\n",
        "sentiments = []\n",
        "for index, row in df.iterrows():\n",
        "    sentiment = get_sentiment_score(stock_symbol, index.strftime('%Y-%m-%d'))\n",
        "    sentiments.append(sentiment)\n",
        "\n",
        "df[\"Sentiment\"] = sentiments\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# === Data Preprocessing ===\n",
        "print(\"Preprocessing data...\")\n",
        "features = [('Close', stock_symbol), ('50_MA', stock_symbol), ('200_MA', stock_symbol), ('Volatility', stock_symbol), ('RSI', stock_symbol), ('MACD', stock_symbol), \"Sentiment\"]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df_scaled = scaler.fit_transform(df[features])\n",
        "\n",
        "print(\"Creating sequences...\")\n",
        "def create_sequences(data, time_steps=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data[i:i+time_steps])\n",
        "        y.append(data[i+time_steps][0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 60\n",
        "X, y = create_sequences(df_scaled, time_steps)\n",
        "print(\"Sequences created.\")\n",
        "\n",
        "# Train-Test Split\n",
        "print(\"Splitting data into training and testing sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "print(f\"Training set size: {len(X_train)}, Testing set size: {len(X_test)}\")\n",
        "\n",
        "# === Transformer-Based Model ===\n",
        "def build_transformer_model(input_shape):\n",
        "    print(\"Building Transformer model...\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "    attn_output = MultiHeadAttention(num_heads=2, key_dim=input_shape[-1])(inputs, inputs)\n",
        "    x = LayerNormalization(epsilon=1e-6)(attn_output + inputs)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "    print(\"Model built successfully.\")\n",
        "    return model\n",
        "\n",
        "model = build_transformer_model((time_steps, len(features)))\n",
        "\n",
        "# Train Model\n",
        "print(\"Training model...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "# === SHAP Explainability ===\n",
        "print(\"Calculating SHAP values using KernelExplainer...\")\n",
        "explainer = shap.KernelExplainer(model.predict, X_train[:100])\n",
        "\n",
        "X_test_2d = X_test[:10].reshape(10 * X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "shap_values = explainer.shap_values(X_test_2d)\n",
        "\n",
        "shap_values_3d = np.reshape(shap_values, (10, X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "X_test_original_shape = np.reshape(X_test_2d, (10, X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "shap.summary_plot(shap_values_3d[0], X_test_original_shape[0], feature_names=features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UrQmztT7WSe2",
        "outputId": "0ce44711-83ae-47a1-b84b-14c88967812e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter stock symbol (e.g., TSLA for Tesla): hdfcbank.ns\n",
            "Fetching data for stock: hdfcbank.ns\n",
            "Stock symbol: hdfcbank.ns\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex([( 'Close', 'HDFCBANK.NS'),\n",
            "            (  'High', 'HDFCBANK.NS'),\n",
            "            (   'Low', 'HDFCBANK.NS'),\n",
            "            (  'Open', 'HDFCBANK.NS'),\n",
            "            ('Volume', 'HDFCBANK.NS')],\n",
            "           names=['Price', 'Ticker'])\n",
            "Price            Close        High         Low        Open      Volume\n",
            "Ticker     HDFCBANK.NS HDFCBANK.NS HDFCBANK.NS HDFCBANK.NS HDFCBANK.NS\n",
            "Date                                                                  \n",
            "2010-01-04  151.915115  153.945755  150.743932  151.407449     3050490\n",
            "2010-01-05  152.048691  153.634015  151.852751  152.298067     8386600\n",
            "2010-01-06  152.151123  153.188703  150.347585  152.654319     6639840\n",
            "2010-01-07  152.547440  157.499351  151.549936  157.499351     6123980\n",
            "2010-01-08  152.747833  153.491503  151.496496  152.476183     7085900\n",
            "Price   Ticker     \n",
            "Close   HDFCBANK.NS    0\n",
            "High    HDFCBANK.NS    0\n",
            "Low     HDFCBANK.NS    0\n",
            "Open    HDFCBANK.NS    0\n",
            "Volume  HDFCBANK.NS    0\n",
            "dtype: int64\n",
            "Price   Ticker     \n",
            "Close   HDFCBANK.NS    float64\n",
            "High    HDFCBANK.NS    float64\n",
            "Low     HDFCBANK.NS    float64\n",
            "Open    HDFCBANK.NS    float64\n",
            "Volume  HDFCBANK.NS      int64\n",
            "dtype: object\n",
            "Stock data fetched successfully.\n",
            "Stock symbol (before indicators): hdfcbank.ns\n",
            "Calculating technical indicators...\n",
            "KeyError during technical indicator calculation: ('Close', 'hdfcbank.ns')\n",
            "MultiIndex([( 'Close', 'HDFCBANK.NS'),\n",
            "            (  'High', 'HDFCBANK.NS'),\n",
            "            (   'Low', 'HDFCBANK.NS'),\n",
            "            (  'Open', 'HDFCBANK.NS'),\n",
            "            ('Volume', 'HDFCBANK.NS')],\n",
            "           names=['Price', 'Ticker'])\n",
            "Preprocessing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index([     ('Close', 'hdfcbank.ns'),      ('50_MA', 'hdfcbank.ns'),\\n           ('200_MA', 'hdfcbank.ns'), ('Volatility', 'hdfcbank.ns'),\\n              ('RSI', 'hdfcbank.ns'),       ('MACD', 'hdfcbank.ns'),\\n                         'Sentiment'],\\n      dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f238f13a406a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'50_MA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'200_MA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Volatility'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'RSI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'MACD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mdf_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating sequences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2784\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{keyarr} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_indexer_level_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([     ('Close', 'hdfcbank.ns'),      ('50_MA', 'hdfcbank.ns'),\\n           ('200_MA', 'hdfcbank.ns'), ('Volatility', 'hdfcbank.ns'),\\n              ('RSI', 'hdfcbank.ns'),       ('MACD', 'hdfcbank.ns'),\\n                         'Sentiment'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ]
    }
  ]
}